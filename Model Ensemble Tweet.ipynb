{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enMBgPJL3YKk"
      },
      "source": [
        "# **LOAD DATASET & LIBRARY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFVUzB2M3Pc6",
        "outputId": "6fe73ead-951c-4843-904a-9ee1360476e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYD8yntyTOvV"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score , f1_score, accuracy_score,confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "lemma = WordNetLemmatizer()\n",
        "lb = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "0GYdX-IYTSBc",
        "outputId": "f023ced4-c4d2-4e87-a738-86b55be3d5f1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/dataset.xls'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-50c485c445ac>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/dataset.xls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dataset.xls'"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_excel('/content/dataset.xls')\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oAMlijvGb_N",
        "outputId": "0981fec8-c745-4798-9b29-b0cf5d8b498e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0eb19dd5d3fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8ZwclllHChP"
      },
      "outputs": [],
      "source": [
        "dataset_cleaned_rows = dataset.dropna()\n",
        "dataset_cleaned_columns = dataset.dropna(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O0qO4oK3PyT"
      },
      "source": [
        "# **PRE PROCESSING** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqnbC_h79Xeb"
      },
      "outputs": [],
      "source": [
        "def Most_Words_used(full_text , num_of_words) :\n",
        "    all_text = ''.join(dataset[full_text].values)\n",
        "\n",
        "    all_text = re.sub(r'http\\S+', '', all_text)\n",
        "    all_text = re.sub(r'@\\S+', '', all_text)\n",
        "    all_text = re.sub(r'#\\S+', '', all_text)\n",
        "    all_text = re.sub(r'\\d+', '',all_text)\n",
        "    all_text = re.sub(r'[^\\w\\s]', '',all_text)\n",
        "\n",
        "\n",
        "    words = all_text.split()\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if not word in stop_words]\n",
        "\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    top_words = word_counts.most_common(num_of_words)\n",
        "\n",
        "    return top_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY7PDs5UH4K1"
      },
      "outputs": [],
      "source": [
        "def DataPrep(full_text) :\n",
        "    full_text = re.sub('<.*?>', '', full_text)\n",
        "    full_text = re.sub(r'http\\S+', '', full_text)\n",
        "    full_text = re.sub(r'@\\S+', '', full_text)\n",
        "    full_text = re.sub(r'#\\S+', '', full_text)\n",
        "    full_text = re.sub(r'\\d+', '', full_text)\n",
        "    full_text = re.sub(r'[^\\w\\s]', '', full_text)\n",
        "    full_text = re.sub(r'@(\\w+)', '', full_text)\n",
        "\n",
        "    tokens = nltk.word_tokenize(full_text)\n",
        "\n",
        "    #remove puncs\n",
        "    punc = list(punctuation)\n",
        "    words = [w for w in tokens if w not in punc]\n",
        "\n",
        "    #remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w.lower() for w in words if not w.lower() in stop_words]\n",
        "\n",
        "    # lemmatization\n",
        "    words = [lemma.lemmatize(w) for w in words]\n",
        "\n",
        "    text = ' '.join(words)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-9r130F38Z8"
      },
      "outputs": [],
      "source": [
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37SUuo-UDiqG"
      },
      "outputs": [],
      "source": [
        "dataset['full_text'] = dataset['full_text'].astype(str).apply(DataPrep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5oWLePHDzLj"
      },
      "outputs": [],
      "source": [
        "print(dataset['full_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD5kTz6MIyhT"
      },
      "outputs": [],
      "source": [
        "print(f'There are around {int(dataset[\"full_text\"].duplicated().sum())} duplicated tweets, we will remove them.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjF-IML-I8sk"
      },
      "outputs": [],
      "source": [
        "dataset.drop_duplicates(\"full_text\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_UMQoEEJDTi"
      },
      "outputs": [],
      "source": [
        "print(f'There are around {int(dataset[\"full_text\"].duplicated().sum())} duplicated tweets, we will remove them.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZSHga9LC7dj"
      },
      "source": [
        "# **VADER LABELLING** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyNNSxgM5d5_"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBgSxVPpfz2U"
      },
      "outputs": [],
      "source": [
        "# Inisialisasi VADER\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Fungsi untuk menentukan kategori urgent atau tidak urgent berdasarkan sentimen\n",
        "def categorize_sentiment(row, urgent_words=None):\n",
        "    sentiment_scores = sia.polarity_scores(row['full_text'])\n",
        "\n",
        "    # Jika terdapat kata-kata tertentu dalam kalimat, kategorikan sebagai 'urgent'\n",
        "    if urgent_words and any(word in row['full_text'] for word in urgent_words):\n",
        "        return 'mendesak'\n",
        "    # Jika nilai sentimen negatif lebih tinggi, kategorikan sebagai 'urgent'\n",
        "    elif sentiment_scores['neg'] > sentiment_scores['pos']:\n",
        "        return 'mendesak'\n",
        "    else:\n",
        "        return 'tidak mendesak'\n",
        "\n",
        "# Terapkan fungsi pada setiap baris data untuk menentukan kategori\n",
        "# Di sini, kita memberikan daftar kata-kata mendesak sebagai contoh, Anda dapat mengubahnya sesuai kebutuhan\n",
        "urgent_keywords = [\"mendesak\", \"darurat\", \"penting\", \"lagi\", \"mati\", \"jenazah\", \"mayat\"]\n",
        "dataset['label'] = dataset.apply(lambda row: categorize_sentiment(row, urgent_words=urgent_keywords), axis=1)\n",
        "\n",
        "# Tampilkan data yang telah ditambahkan kategori urgent atau tidak urgent\n",
        "print(dataset[['full_text', 'label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWsffdDEgUHX"
      },
      "outputs": [],
      "source": [
        "dataset['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlwt\n",
        "\n",
        "# Simpan dataframe yang sudah dilabeli ke file Excel\n",
        "labeled_file_path = 'data_twitter_labeled.xls'  # Ubah ekstensi file sesuai kebutuhan, misalnya .xls atau .xlsx\n",
        "dataset.to_excel(labeled_file_path, index=False)\n",
        "\n",
        "# Berikan tautan untuk mengunduh file labeled Excel\n",
        "download_link = f'<a href=\"{labeled_file_path}\" download>Klik di sini</a> untuk mengunduh file labeled Excel.'"
      ],
      "metadata": {
        "id": "2iI8lOxc94_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('data_twitter_labeled.xls')"
      ],
      "metadata": {
        "id": "n8cepU-b-gt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvFqSEMTr1wx"
      },
      "source": [
        "# **LOAD DATASET LABELED**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNsKZA_vrwGo",
        "outputId": "82cfaeeb-df18-4696-bb9d-8c1539115a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.25.2)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZTNfhN2sWKp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#preprocesing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "#split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# mb25\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "1pS1RCJqsXTa",
        "outputId": "d60d641f-dad8-4195-8f4d-2b1f061d91d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       created_at               id_str  \\\n",
              "0  Mon Dec 04 12:01:29 +0000 2023  1731640000000000000   \n",
              "1  Fri Dec 01 08:00:00 +0000 2023  1730500000000000000   \n",
              "2  Fri Dec 01 06:14:11 +0000 2023  1730470000000000000   \n",
              "3  Fri Dec 01 05:42:40 +0000 2023  1730460000000000000   \n",
              "4  Tue Nov 28 03:50:18 +0000 2023  1729350000000000000   \n",
              "\n",
              "                                           full_text  quote_count  \\\n",
              "0  menurut laporan bps sumatra utara menjadi prov...            0   \n",
              "1  diguyur hujan deras jalan di lebak banten long...            0   \n",
              "2  bapakibu terdpt jalan yang rusak di daerah gra...            0   \n",
              "3  catatan infrastruktur jalan di indonesia berda...            0   \n",
              "4  jenazah pria bernama arju di polewali mandar t...            0   \n",
              "\n",
              "   reply_count  retweet_count  favorite_count lang          user_id_str  \\\n",
              "0            0              0               0   in  1316330000000000000   \n",
              "1            0              0               0   in             61377303   \n",
              "2            1              1               0   in  1574830000000000000   \n",
              "3            1             30              30   in             53878998   \n",
              "4            0              0               1   in            375995332   \n",
              "\n",
              "   conversation_id_str      username  \\\n",
              "0  1731640000000000000    databoksid   \n",
              "1  1730500000000000000  Lintas_MNCTV   \n",
              "2  1730470000000000000  Eddy30749724   \n",
              "3  1730460000000000000  datanesia_id   \n",
              "4  1729350000000000000  SeputariNews   \n",
              "\n",
              "                                           tweet_url           label  \n",
              "0  https://twitter.com/databoksid/status/17316448...  tidak mendesak  \n",
              "1  https://twitter.com/Lintas_MNCTV/status/173049...  tidak mendesak  \n",
              "2  https://twitter.com/Eddy30749724/status/173047...  tidak mendesak  \n",
              "3  https://twitter.com/datanesia_id/status/173046...  tidak mendesak  \n",
              "4  https://twitter.com/SeputariNews/status/172934...        mendesak  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc938a62-1ac9-48a9-9878-0908627307c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>id_str</th>\n",
              "      <th>full_text</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>lang</th>\n",
              "      <th>user_id_str</th>\n",
              "      <th>conversation_id_str</th>\n",
              "      <th>username</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mon Dec 04 12:01:29 +0000 2023</td>\n",
              "      <td>1731640000000000000</td>\n",
              "      <td>menurut laporan bps sumatra utara menjadi prov...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>in</td>\n",
              "      <td>1316330000000000000</td>\n",
              "      <td>1731640000000000000</td>\n",
              "      <td>databoksid</td>\n",
              "      <td>https://twitter.com/databoksid/status/17316448...</td>\n",
              "      <td>tidak mendesak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fri Dec 01 08:00:00 +0000 2023</td>\n",
              "      <td>1730500000000000000</td>\n",
              "      <td>diguyur hujan deras jalan di lebak banten long...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>in</td>\n",
              "      <td>61377303</td>\n",
              "      <td>1730500000000000000</td>\n",
              "      <td>Lintas_MNCTV</td>\n",
              "      <td>https://twitter.com/Lintas_MNCTV/status/173049...</td>\n",
              "      <td>tidak mendesak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fri Dec 01 06:14:11 +0000 2023</td>\n",
              "      <td>1730470000000000000</td>\n",
              "      <td>bapakibu terdpt jalan yang rusak di daerah gra...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>in</td>\n",
              "      <td>1574830000000000000</td>\n",
              "      <td>1730470000000000000</td>\n",
              "      <td>Eddy30749724</td>\n",
              "      <td>https://twitter.com/Eddy30749724/status/173047...</td>\n",
              "      <td>tidak mendesak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fri Dec 01 05:42:40 +0000 2023</td>\n",
              "      <td>1730460000000000000</td>\n",
              "      <td>catatan infrastruktur jalan di indonesia berda...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>in</td>\n",
              "      <td>53878998</td>\n",
              "      <td>1730460000000000000</td>\n",
              "      <td>datanesia_id</td>\n",
              "      <td>https://twitter.com/datanesia_id/status/173046...</td>\n",
              "      <td>tidak mendesak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tue Nov 28 03:50:18 +0000 2023</td>\n",
              "      <td>1729350000000000000</td>\n",
              "      <td>jenazah pria bernama arju di polewali mandar t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>in</td>\n",
              "      <td>375995332</td>\n",
              "      <td>1729350000000000000</td>\n",
              "      <td>SeputariNews</td>\n",
              "      <td>https://twitter.com/SeputariNews/status/172934...</td>\n",
              "      <td>mendesak</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc938a62-1ac9-48a9-9878-0908627307c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc938a62-1ac9-48a9-9878-0908627307c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc938a62-1ac9-48a9-9878-0908627307c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2da8bf3-d806-461f-a703-c51914b1cded\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2da8bf3-d806-461f-a703-c51914b1cded')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2da8bf3-d806-461f-a703-c51914b1cded button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset_label",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset_label = pd.read_excel('/content/data_twitter_labeled.xls')\n",
        "dataset_label.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzatJIE5tHyr"
      },
      "source": [
        "# **SPLIT DATASET (80:20)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8PT4f_pslag"
      },
      "outputs": [],
      "source": [
        "# Membuat DataFrame dari data sentimen\n",
        "dataset_label = pd.DataFrame(dataset_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT_YksrGs6tz"
      },
      "outputs": [],
      "source": [
        "X = dataset_label['full_text'].tolist()\n",
        "y = dataset_label['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t0E0h9UtGwR",
        "outputId": "28aa8f0b-d590-43db-f0fd-7c4abd5c7450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data latih: 4415\n",
            "Jumlah data uji: 1104\n"
          ]
        }
      ],
      "source": [
        "# Jumlah data latih\n",
        "num_train = len(X_train)\n",
        "print(\"Jumlah data latih:\", num_train)\n",
        "\n",
        "# Jumlah data uji\n",
        "num_test = len(X_test)\n",
        "print(\"Jumlah data uji:\", num_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWxkFtdRupDL"
      },
      "outputs": [],
      "source": [
        "dataset = dataset_label.dropna(subset=['full_text'])\n",
        "\n",
        "# Extract the 'text' column as a list again\n",
        "X_train = dataset['full_text'].tolist()\n",
        "\n",
        "# Define n-gram range\n",
        "ngram_range = (1, 2)\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
        "\n",
        "# Fit and transform the data\n",
        "X_train_counts = vectorizer.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oCpMPV9vVV8",
        "outputId": "cedb65f0-400d-4767-afa1-1f5939cb55db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      __  __ xl  ___  ___ habis  ____  _____  ______  _________  _a  aa  ...  \\\n",
            "0      0      0    0          0     0      0       0          0   0   0  ...   \n",
            "1      0      0    0          0     0      0       0          0   0   0  ...   \n",
            "2      0      0    0          0     0      0       0          0   0   0  ...   \n",
            "3      0      0    0          0     0      0       0          0   0   0  ...   \n",
            "4      0      0    0          0     0      0       0          0   0   0  ...   \n",
            "...   ..    ...  ...        ...   ...    ...     ...        ...  ..  ..  ...   \n",
            "5513   0      0    0          0     0      0       0          0   0   0  ...   \n",
            "5514   0      0    0          0     0      0       0          0   0   0  ...   \n",
            "5515   0      0    0          0     0      0       0          0   0   0  ...   \n",
            "5516   0      0    0          0     0      0       0          0   0   0  ...   \n",
            "5517   0      0    0          0     0      0       0          0   0   0  ...   \n",
            "\n",
            "      ðÿƒ im  ðÿƒ sinyalnya  ðÿƒðÿââïðÿƒðÿââï  ðÿƒðÿƒ  ðÿƒðÿƒ fakk  \\\n",
            "0          0              0                 0       0            0   \n",
            "1          0              0                 0       0            0   \n",
            "2          0              0                 0       0            0   \n",
            "3          0              0                 0       0            0   \n",
            "4          0              0                 0       0            0   \n",
            "...      ...            ...               ...     ...          ...   \n",
            "5513       0              0                 0       0            0   \n",
            "5514       0              0                 0       0            0   \n",
            "5515       0              0                 0       0            0   \n",
            "5516       0              0                 0       0            0   \n",
            "5517       0              0                 0       0            0   \n",
            "\n",
            "      ðÿƒðÿƒ problematika  ðÿƒðÿƒðÿƒ  ðÿˆðÿˆ  ðÿˆðÿˆ trim  ðÿˆðÿˆðÿˆ  \n",
            "0                       0          0       0            0          0  \n",
            "1                       0          0       0            0          0  \n",
            "2                       0          0       0            0          0  \n",
            "3                       0          0       0            0          0  \n",
            "4                       0          0       0            0          0  \n",
            "...                   ...        ...     ...          ...        ...  \n",
            "5513                    0          0       0            0          0  \n",
            "5514                    0          0       0            0          0  \n",
            "5515                    0          0       0            0          0  \n",
            "5516                    0          0       0            0          0  \n",
            "5517                    0          0       0            0          0  \n",
            "\n",
            "[5518 rows x 72572 columns]\n"
          ]
        }
      ],
      "source": [
        "df_counts = pd.DataFrame(X_train_counts.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "print(df_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jkblo5hvHeB"
      },
      "source": [
        "# **BM25**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72ANyH_tvExY"
      },
      "outputs": [],
      "source": [
        "# Membangun BM25 Vectorizer\n",
        "bm25 = BM25Okapi(X_train)\n",
        "\n",
        "# Mengubah data pelatihan menjadi vektor BM25\n",
        "X_train_bm25 = [bm25.get_scores(doc) for doc in X_train]\n",
        "\n",
        "# Mengubah data uji menjadi vektor BM25\n",
        "X_test_bm25 = [bm25.get_scores(doc) for doc in X_test]\n",
        "\n",
        "# Menggabungkan X_train_bm25 dan X_test_bm25\n",
        "X_train_bm25_combined = np.vstack(X_train_bm25)\n",
        "X_test_bm25_combined = np.vstack(X_test_bm25)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(sorted(list(X_train_bm25_combined[i,:]), reverse=True)[:20])\n",
        "    print('--------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTjQervZA1zb",
        "outputId": "b7647de0-bcda-4fd6-e9a6-341d705bcd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[170.41367199877968, 169.39121512624988, 168.96216348675145, 168.92913189160637, 168.85094908543255, 168.74805329229807, 168.6424593591305, 168.5721795040749, 168.43732267968682, 168.39887958495058, 168.39396421086767, 168.36648406198725, 168.35878101688118, 168.3436852294359, 168.33846054617652, 168.3300693231341, 168.31180984058983, 168.28489851579508, 168.27227504875475, 168.2152866509564]\n",
            "--------------------------------------------------\n",
            "[83.11927293279561, 82.89808139059352, 82.89698941634593, 82.86860389050942, 82.84152202096064, 82.72148178685792, 82.70469599756302, 82.69237830821511, 82.67331575876962, 82.61659388809647, 82.60402796590832, 82.60270558459113, 82.58120172425842, 82.57652405222318, 82.57245494576944, 82.57205094120275, 82.55199178004729, 82.54437247092719, 82.50493929365294, 82.50344803349509]\n",
            "--------------------------------------------------\n",
            "[131.41638749554542, 130.6570138244862, 130.38396664787254, 130.12980760638263, 129.83890305335368, 129.72240908398652, 129.49951363110873, 129.47780187115848, 129.2724540711003, 129.17268581457174, 129.15605409628884, 128.95696357299545, 128.89601684593345, 128.84122688514495, 128.78942271065114, 128.6520182630801, 128.64285269003764, 128.53057450269782, 128.3884450590679, 128.20851474953176]\n",
            "--------------------------------------------------\n",
            "[141.82109907271976, 141.72126576919607, 141.65026562558867, 141.63712070937635, 141.5076145453026, 141.50714530140633, 141.47534908722326, 141.4475097900624, 141.38679161903644, 141.3843509493452, 141.300241882305, 141.25133104460187, 141.2239170993593, 141.2146649265213, 141.19248322267322, 141.19193420108584, 141.17396171728677, 141.06054780042356, 141.03231344286343, 140.98609976537924]\n",
            "--------------------------------------------------\n",
            "[171.24025739386164, 170.6608539495512, 170.47885273507967, 170.30097918555995, 170.03541573801175, 169.88908952132144, 169.5083138173309, 169.45901878252238, 169.25630415530395, 169.15545597613283, 169.14136034545362, 169.06085998528116, 169.01997510827576, 168.99341507383494, 168.901954827447, 168.82789382636128, 168.68823354600403, 168.515720021778, 168.50141520469467, 168.41757311044026]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO57Owsv2Iag"
      },
      "source": [
        "# **WORD EMBEDDING**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "39BQ75kQhfe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model Word2Vec\n",
        "tokenized_text = dataset['full_text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "word2vec_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, sg=0)"
      ],
      "metadata": {
        "id": "I2WeEfPaj890"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat fungsi untuk mengonversi teks menjadi representasi vektor Word2Vec\n",
        "def text_to_vector(text, model):\n",
        "    words = word_tokenize(text.lower())\n",
        "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    if word_vectors:\n",
        "        text_vector = sum(word_vectors) / len(word_vectors)\n",
        "    else:\n",
        "        text_vector = [0] * model.vector_size\n",
        "    return text_vector"
      ],
      "metadata": {
        "id": "UqVtEIiwlOkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengonversi teks menjadi representasi vektor Word2Vec\n",
        "dataset['text_vectors'] = dataset['full_text'].apply(lambda x: text_to_vector(x, word2vec_model))\n"
      ],
      "metadata": {
        "id": "5PD9sGmvkBmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELLING**"
      ],
      "metadata": {
        "id": "eRzRz7hhmKt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan dataset menjadi data latih dan data uji\n",
        "X = dataset['text_vectors'].tolist()  # Features\n",
        "y = dataset['label']  # Labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gkjsNNvvlYHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression()\n",
        "model2 = DecisionTreeClassifier()\n",
        "model3 = RandomForestClassifier()\n",
        "model4 = SVC(probability=True)\n",
        "\n",
        "ensemble_model = VotingClassifier(estimators=[('lr', model1), ('dt', model2), ('rf', model3), ('svm', model4)], voting='soft')\n",
        "\n",
        "ensemble_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KqngP6b4lcj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat prediksi dengan model ensemble pada data uji\n",
        "y_pred_ensemble = ensemble_model.predict(X_test)\n",
        "y_pred_proba_ensemble = ensemble_model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "MCDDz1yClhSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_ensemble)\n",
        "\n",
        "\n",
        "# Membuat heatmap dari confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix - Model Ensemble\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qNh9gdJ-rO--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Mengubah y_pred_ensemble menjadi array numpy\n",
        "y_pred_ensemble = np.array(y_pred_ensemble)\n",
        "\n",
        "# Memastikan jumlah sampel yang konsisten\n",
        "min_len = min(len(y_test), len(y_pred_ensemble))\n",
        "y_test = y_test[:min_len]\n",
        "y_pred_ensemble = y_pred_ensemble[:min_len]\n",
        "\n",
        "# Menampilkan metrik evaluasi\n",
        "accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
        "precision = precision_score(y_test, y_pred_ensemble, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_ensemble, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_ensemble, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "wfkOCS6erjp0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "enMBgPJL3YKk",
        "6O0qO4oK3PyT",
        "AZSHga9LC7dj",
        "2Jkblo5hvHeB",
        "HO57Owsv2Iag",
        "eRzRz7hhmKt2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}